{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_core.documents import Document\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import uuid, pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Ed\\RAGs\\fortive_rag_v1\\Multimodal_RAG\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "sntnc_trnsfrmr_embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "# embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Input data\n",
    "qa_list = [\n",
    "    {\"question\": \"What is the capital of France?\", \"answer\": \"Paris\"},\n",
    "    {\"question\": \"What is 2 + 2?\", \"answer\": \"4\"},\n",
    "    {\"question\": \"Who wrote 'Harry Potter'?\", \"answer\": \"J.K. Rowling\"},\n",
    "    {\"question\": \"What is the largest planet in our solar system?\", \"answer\": \"Jupiter\"},\n",
    "    {\"question\": \"How many continents are there on Earth?\", \"answer\": \"7\"}\n",
    "]\n",
    "\n",
    "# Create fake_whole_documents and docs\n",
    "whole_docs = []\n",
    "vector_store_docs = []\n",
    "\n",
    "for qa in qa_list:\n",
    "    unique_id = str(uuid.uuid4())\n",
    "    whole_docs.append((unique_id, Document(page_content=str(qa))))\n",
    "    vector_store_docs.append(Document(page_content=qa[\"question\"], metadata={\"doc_id\": unique_id}))\n",
    "\n",
    "docstore = InMemoryStore()\n",
    "docstore.mset(whole_docs)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrm_b = Chroma.from_documents(documents=vector_store_docs, embedding=sntnc_trnsfrmr_embeddings, collection_metadata={\"hnsw:space\": \"cosine\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chroma_cache_vector = Chroma(persist_directory=\"./src/vector_dbs/chroma_cache_vector\", embedding_function=sntnc_trnsfrmr_embeddings)\n",
    "cache_path = \"./chroma_cache_vector\"\n",
    "chroma_cache_vector = Chroma(persist_directory=cache_path, embedding_function=sntnc_trnsfrmr_embeddings, collection_metadata={\"hnsw:space\": \"cosine\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.storage import LocalFileStore\n",
    "\n",
    "# Instantiate the LocalFileStore with the root path\n",
    "cache_docstore = LocalFileStore(r\"D:\\Ed\\RAGs\\fortive_rag_v1\\Multimodal_RAG\\src\\vector_dbs\\cache_docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_docstore.mset([(\"key3\", b\"value1\"), (\"key4\", b\"value2\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b\"content='The accuracy of CI1A J Thermocouple ranges from 0 to 115\\xc2\\xb0C (32 to 240\\xc2\\xb0F) with an accuracy of \\xc2\\xb12% or \\xc2\\xb13\\xc2\\xb0C (-6\\xc2\\xb0F).' additional_kwargs={} response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-01-14T18:41:00.8312193Z', 'done': True, 'done_reason': 'stop', 'total_duration': 4708192200, 'load_duration': 3101218400, 'prompt_eval_count': 208, 'prompt_eval_duration': 188000000, 'eval_count': 41, 'eval_duration': 1416000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-3fb02d19-741f-426c-8769-7f2b781d2f51-0' usage_metadata={'input_tokens': 208, 'output_tokens': 41, 'total_tokens': 249}\"]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache_docstore.mget(['367cf847-4803-483e-9361-f2362390613f'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache_update(question, answer):\n",
    "    # Create fake_whole_documents and docs\n",
    "    whole_docs = []\n",
    "    vector_store_docs = []\n",
    "    unique_id = str(uuid.uuid4())\n",
    "    whole_docs.append((unique_id, Document(page_content=str(question))))\n",
    "    vector_store_docs.append(Document(page_content=answer, metadata={\"doc_id\": unique_id}))\n",
    "\n",
    "    cache_docstore.mset(whole_docs)  \n",
    "    chroma_cache_vector.add_documents(vector_store_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache_retrival(question):\n",
    "    rslt = chroma_cache_vector.similarity_search_with_score(question)\n",
    "    rslt_df = pd.DataFrame(rslt, columns=[\"doc\", \"score\"])  \n",
    "    rlvnt_df = rslt_df[rslt_df[\"score\"] <= 0.1]\n",
    "    if rlvnt_df.empty:\n",
    "        return None\n",
    "    else:\n",
    "        try:\n",
    "            cache_id = rlvnt_df.head(1)['doc'].values[0].metadata['doc_id']\n",
    "            answer = cache_docstore.get(cache_id).page_content\n",
    "            return answer\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama, OllamaLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_llama3 = ChatOllama(\n",
    "    model=\"llama3.2:1b\",\n",
    "    temperature=0,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='A man walked into a library and asked the librarian, \"Do you have any books on Pavlov\\'s dogs?\" The librarian replied, \"It rings a bell, but I\\'m not sure if it\\'s here.\"', additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-01-14T18:49:02.963759Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2621389800, 'load_duration': 1549472000, 'prompt_eval_count': 29, 'prompt_eval_duration': 75000000, 'eval_count': 44, 'eval_duration': 994000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-f3afc8af-89af-4cdd-bf21-7543d676afb4-0', usage_metadata={'input_tokens': 29, 'output_tokens': 44, 'total_tokens': 73})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "ai_message = llm_llama3.invoke([HumanMessage(\"Tell me a joke\")])\n",
    "ai_message # <-- AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A man walked into a library and asked the librarian, \"Do you have any books on Pavlov\\'s dogs?\" The librarian replied, \"It rings a bell, but I\\'m not sure if it\\'s here.\"'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from pptx import Presentation\n",
    "from pptx.util import Inches\n",
    "\n",
    "def pdf_to_ppt(pdf_file, ppt_file):\n",
    "    pdf_document = fitz.open(pdf_file)\n",
    "    presentation = Presentation()\n",
    "\n",
    "    for page_num in range(len(pdf_document)):\n",
    "        page = pdf_document[page_num]\n",
    "        pix = page.get_pixmap()\n",
    "        image_path = f\"page_{page_num + 1}.png\"\n",
    "        pix.save(image_path)\n",
    "\n",
    "        slide = presentation.slides.add_slide(presentation.slide_layouts[5])\n",
    "        left = Inches(0.5)\n",
    "        top = Inches(0.5)\n",
    "        slide.shapes.add_picture(image_path, left, top, width=Inches(9), height=Inches(7))\n",
    "\n",
    "    presentation.save(ppt_file)\n",
    "\n",
    "pdf_to_ppt(\"input.pdf\", \"output.pptx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfWriter, PdfReader\n",
    "\n",
    "# Read the input PDF\n",
    "input_pdf = PdfReader(\"document.pdf\")\n",
    "\n",
    "# Iterate through each page and create a new PDF file for each page\n",
    "for i in range(len(input_pdf.pages)):\n",
    "    output = PdfWriter()\n",
    "    output.add_page(input_pdf.pages[i])\n",
    "    \n",
    "    # Write the new PDF file\n",
    "    with open(f\"document-page{i}.pdf\", \"wb\") as output_stream:\n",
    "        output.write(output_stream)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
